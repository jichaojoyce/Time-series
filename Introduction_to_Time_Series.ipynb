{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Introduction to Time Series.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3_qzm15CrqKp"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipyhIb3zrqJm",
        "colab_type": "text"
      },
      "source": [
        "# Outline\n",
        "\n",
        "This project has several sections and will provide you a concise introduction to time series concepts in R. We will learn the essential theory and also practice fitting the four main types of time series models, getting you up and running with all the basics in a little more than an hour!\n",
        "\n",
        "(1) Introduction to Rhyme Environment\n",
        "\n",
        "(2) Time Series Data Overview (Theory)\n",
        "\n",
        "(3) Why Time Series? (Theory)\n",
        "\n",
        "(4) Key Concepts: Autocorrelation / Autocovariance (Theory)\n",
        "\n",
        "(5) Key Concepts: Stationarity (Theory)\n",
        "\n",
        "(6) Checking for Stationarity (Practice)\n",
        "\n",
        "(7) Transforming for Stationarity: Differencing (Practice)\n",
        "\n",
        "(8) Transforming for Stationarity: Detrending (Practice)\n",
        "\n",
        "(9) Basic Model Types: AR(p), MA(q), ARMA(p,q), ARIMA(p,d,q), Decomposition (Theory)\n",
        "\n",
        "(10) Fitting AR / MA / ARMA / ARIMA models with the Box Jenkins Method (Theory)\n",
        "\n",
        "(11) Box Jenkins Method: Checking for Stationarity (Practice)\n",
        "\n",
        "(12) Box Jenkins Method: Transforming for Stationarity & Identifying Model Parameters (Practice)\n",
        "\n",
        "(13) Box Jenkins Method: Checking the Residuals of the Model Fit (Practice)\n",
        "\n",
        "(14) Making a Forecast for Each Model (Practice)\n",
        "\n",
        "(15) Fitting STL (Seasonal Trend Loess) Decomposition Models (Practice)\n",
        "\n",
        "(16) Where to go Next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY_H0da8rqJn",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to Rhyme Environment\n",
        "\n",
        "Now, let's load the R packages we will need for this project (they should be already installed on your virtual machine)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzUe3CDwrqJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "bd281997-778e-4ec4-db1a-260adf459e90"
      },
      "source": [
        "#load required r packages\n",
        "library(IRdisplay)\n",
        "library(magrittr)\n",
        "library(tidyverse)\n",
        "library(scales)\n",
        "library(gridExtra)\n",
        "library(forecast)\n",
        "library(tseries)\n",
        "library(ggthemes)\n",
        "theme_set(theme_economist())\n",
        "\n",
        "#load helper R functions\n",
        "setwd(\"C:/Users/Administrator/Desktop/Time Series Project Materials/\")\n",
        "source(\"R Functions/compare_models_function.R\")\n",
        "source(\"R Functions/sim_random_walk_function.R\")\n",
        "source(\"R Functions/sim_stationary_example_function.R\")\n",
        "\n",
        "print(\"Loading is completed\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n",
            "\n",
            "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.2     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
            "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.0.3     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.0\n",
            "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
            "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
            "\n",
            "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
            "\u001b[31m✖\u001b[39m \u001b[34mtidyr\u001b[39m::\u001b[32mextract()\u001b[39m   masks \u001b[34mmagrittr\u001b[39m::extract()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m    masks \u001b[34mstats\u001b[39m::filter()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m       masks \u001b[34mstats\u001b[39m::lag()\n",
            "\u001b[31m✖\u001b[39m \u001b[34mpurrr\u001b[39m::\u001b[32mset_names()\u001b[39m masks \u001b[34mmagrittr\u001b[39m::set_names()\n",
            "\n",
            "\n",
            "Attaching package: ‘scales’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:purrr’:\n",
            "\n",
            "    discard\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:readr’:\n",
            "\n",
            "    col_factor\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in library(gridExtra): there is no package called ‘gridExtra’\nTraceback:\n",
            "1. library(gridExtra)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ueF6wfprqJs",
        "colab_type": "text"
      },
      "source": [
        "# Time Series Data Overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "RgHmGQDvrqJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "acb83686-1d27-421b-d9bd-2b8cff8dd610"
      },
      "source": [
        "display_png(file=\"Images/time_series_dinosaur.png\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning message in file(con, \"rb\"):\n",
            "“cannot open file 'Images/time_series_dinosaur.png': No such file or directory”\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in file(con, \"rb\"): cannot open the connection\nTraceback:\n",
            "1. display_png(file = \"Images/time_series_dinosaur.png\")",
            "2. display_raw(\"image/png\", TRUE, data, file, img_metadata(width, \n .     height))",
            "3. prepare_content(isbinary, data, file)",
            "4. read_all(file, isbinary)",
            "5. read(size)",
            "6. readBin(file, \"raw\", s)",
            "7. file(con, \"rb\")"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ2uaecQrqJy",
        "colab_type": "text"
      },
      "source": [
        "(Univariate) time series data is defined as sequence data over time: $X_1, X_2, ... , X_T$\n",
        "\n",
        "where $t$ is the time period and $X_t$ is the value of the time series at a particular point\n",
        "\n",
        "Examples: daily temperatures in Boston, US presidential election turnout by year, minute stock prices\n",
        "\n",
        "Variables in time series models generally fall into three categories:\n",
        "\n",
        "(1) endogenous\n",
        "\n",
        "(2) random noise\n",
        "\n",
        "(3) exogenous\n",
        "\n",
        "All time series models involve (1) and (2) but (3) is optional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWObm9YerqJz",
        "colab_type": "text"
      },
      "source": [
        "# Why Time Series?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bELzJpQRrqJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "b63954d5-f9c6-45c5-8085-ee31ae1751be"
      },
      "source": [
        "display_png(file=\"Images/time_series_complication.png\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning message in file(con, \"rb\"):\n",
            "“cannot open file 'Images/time_series_complication.png': No such file or directory”\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in file(con, \"rb\"): cannot open the connection\nTraceback:\n",
            "1. display_png(file = \"Images/time_series_complication.png\")",
            "2. display_raw(\"image/png\", TRUE, data, file, img_metadata(width, \n .     height))",
            "3. prepare_content(isbinary, data, file)",
            "4. read_all(file, isbinary)",
            "5. read(size)",
            "6. readBin(file, \"raw\", s)",
            "7. file(con, \"rb\")"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dWlURnLrqJ5",
        "colab_type": "text"
      },
      "source": [
        "The answer is that:\n",
        "\n",
        "(1) many forecasting tasks actually involve small samples which makes machine learning less effective\n",
        "\n",
        "(2) time series models are more interpretable and less black box than machine learning algorithms\n",
        "\n",
        "(2) time series appropriately accounts for forecasting uncertainty.\n",
        "\n",
        "As an example, lets look at the following data generating process known as a random walk: $X_t=X_{t-1}+\\epsilon_t$\n",
        "\n",
        "We can compare the forecasting performance of linear regression to that of a basic time series model known as an AR(1) model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_rf0ZkRrqJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run function to compare linear regression to basic AR(1) time series model\n",
        "compare.models(n=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWD_RNW8rqJ9",
        "colab_type": "text"
      },
      "source": [
        "# Key Concepts: Autocorrelation/Autocovariance\n",
        "\n",
        "Autocorrelation/autocovariance refers to the correlation/covariance between two observations in the time series at different points.\n",
        "\n",
        "The central idea behind it is how related the data/time series is over time.\n",
        "\n",
        "For ease of interpretation we typically focus on autocorrelation i.e. what is the correlation between $X_t$ and $X_{t+p}$ for some integer $p$.\n",
        "\n",
        "A related concept is partial autocorrelation that computes the correlation adjusting for previous lags/periods i.e. the autocorrelation between $X_t$ and $X_{t+p}$ adjusting for the correlation of $X_t$ and $X_{t+1}$, … , $X_{t+p-1}$.\n",
        "\n",
        "When analyzing time series we usually view autocorrelation/partial autocorrelation in ACF/PACF plots.\n",
        "\n",
        "Let's view this for the random walk model we analyzed above: $X_t=X_{t-1}+\\epsilon_t$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_YNWUpArqJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#simulate random walk\n",
        "dat<-sim.random.walk()\n",
        "\n",
        "#plot random walk\n",
        "dat %>% ggplot(aes(t,X)) + geom_line() + xlab(\"T\") + ylab(\"X\") + ggtitle(\"Time Series Plot\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAIx4riPrqKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ACF plot\n",
        "ggAcf(dat$X,type=\"correlation\") + ggtitle(\"Autocorrelation ACF Plot\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av1i8UsMrqKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PACF plot\n",
        "ggAcf(dat$X,type=\"partial\") + ggtitle(\"Partial Autocorrelation PACF Plot\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpc1GRROrqKN",
        "colab_type": "text"
      },
      "source": [
        "# Key Concepts: Stationarity\n",
        "\n",
        "The second key concept in time series is stationarity.\n",
        "\n",
        "While the concept can get quite technical, the basic idea is examining whether the distribution of the data over time is consistent.\n",
        "\n",
        "There are two main forms of stationarity.\n",
        "\n",
        "(1) Strict stationarity imples:\n",
        "\n",
        "The cumulative distribution function of the data does not depend on time:\n",
        "\n",
        "$F_X(X_1,...,X_T)=F_X(X_{1+\\Delta},...,X_{T+\\Delta})$ $\\forall \\Delta\\in\\mathbb{R}$ \n",
        "\n",
        "(2) Weak stationarity implies:\n",
        "\n",
        "- the mean of the time series is constant\n",
        "\n",
        "$E(X_t)=E(X_{t+\\Delta})$\n",
        "\n",
        "- the autocovariance/autocorrelation only depends on the time difference between points\n",
        "\n",
        "$ACF(X_{t},X_{t+\\Delta-1})=ACF(X_1,X_{\\Delta})$\n",
        "\n",
        "- the time series has a finite variance\n",
        "\n",
        "$Var(X_\\Delta)<\\infty$  $\\forall \\Delta\\in\\mathbb{R}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4IXAIq1rqKO",
        "colab_type": "text"
      },
      "source": [
        "# Checking for Stationarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeSyb-GGrqKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create three time series for example\n",
        "df<-sim.stationary.example(n=1000)\n",
        "head(df);dim(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9bAYQJFrqKT",
        "colab_type": "text"
      },
      "source": [
        "- Check a plot of the time series over time and look for constant mean and finite variance i.e. values appear bounded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GhozMiTrqKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot nonstationary and stationary time series\n",
        "g1 = ggplot(df,aes(x=t,y=X1))+geom_line()+xlab('T')+ylab('X1')+ggtitle(\"Nonstationary\")\n",
        "g2 = ggplot(df,aes(x=t,y=X3))+geom_line()+xlab('T')+ylab('X3')+ggtitle(\"Nonstationary\")\n",
        "grid.arrange(g1,g2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Htg9USB3rqKW",
        "colab_type": "text"
      },
      "source": [
        "- Look at the ACF plot and see if it dies off quickly as opposed to a gradual decline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iWZsjMKrqKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ACF for nonstationary and stationary time series\n",
        "g1 = ggAcf(df$X1,type='correlation')+xlab('T')+ylab('X1')+ggtitle(\"Nonstationary\")\n",
        "g2 = ggAcf(df$X3,type='correlation')+xlab('T')+ylab('X3')+ggtitle(\"Stationary\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmhqI5HXrqKb",
        "colab_type": "text"
      },
      "source": [
        "- Perform unit root tests such as the Augmented Dickey–Fuller test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTgj9F87rqKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#perform unit test; nonstationary example has large, non-significant p-value\n",
        "adf.test(df$X1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5yXLPVXrqKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#perform unit test; stationary example has small, significant p-value\n",
        "adf.test(df$X3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ7YkRkArqKi",
        "colab_type": "text"
      },
      "source": [
        "# Transforming for Stationarity\n",
        "\n",
        "## Differencing\n",
        "\n",
        "Differencing involves taking differences between successive time series values.\n",
        "\n",
        "The order of differencing is defined as p for $X_t-X_{t-p}$.\n",
        "\n",
        "Let's transform a nonstationary time series to stationary by differencing with the random walk model.\n",
        "\n",
        "In a random walk $X_t=X_{t-1}+\\epsilon_t$ where $\\epsilon_t\\sim N(0,\\sigma^2)$ iid.\n",
        "\n",
        "Differencing with an order of one means that $\\tilde{X}_t=X_t-X_{t-1}=\\epsilon_t$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ3MAJiUrqKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#difference time series to make stationary\n",
        "diff = df$X1 - lag(df$X1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn58jcL2rqKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot original and differenced time series\n",
        "g1 = ggAcf(df$X1,type='correlation')\n",
        "g2 = ggAcf(diff,type='correlation')\n",
        "grid.arrange(g1,g2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_qzm15CrqKp",
        "colab_type": "text"
      },
      "source": [
        "## Detrending\n",
        "\n",
        "Detrending involves removing a deterministic relationship with time.\n",
        "\n",
        "As an example suppose we have the following data generating process $X_t=B_t+\\epsilon_t$ where $\\epsilon_t\\sim N(0,\\sigma^2)$ iid.\n",
        "\n",
        "Detrending involves using the transformed time series $\\tilde{X}_t=X_t-Bt=\\epsilon_t$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aTcwToUrqKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#detrend time series to make stationary\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgHp-mGYrqKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot original and detrended time series\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii2aUFhdrqKx",
        "colab_type": "text"
      },
      "source": [
        "# Basic Model Types: AR(p), MA(q), ARMA(p,q), ARIMA(p,d,q), Decomposition\n",
        "\n",
        "## Autoregressive AR(p) Models\n",
        "\n",
        "AR models specify $X_t$ as a function of lagged time series values $X_{t-1}$, $X_{t-2}$, ...\n",
        "\n",
        "i.e $X_t=\\mu+\\phi_1 X_{t-1}+...+\\phi_p X_{t-p}+\\epsilon_t$\n",
        "\n",
        "where $\\mu$ is a mean term and $\\epsilon_t\\overset{iid}\\sim N(0,\\sigma^2)$ is a random error.\n",
        "\n",
        "When fitting an AR model the key choice is p, the number of lags to include.\n",
        "\n",
        "## Moving Average MA(q) Models\n",
        "\n",
        "MA models specify $X_t$ using random noise lags:\n",
        "\n",
        "$X_t=\\mu+\\epsilon_t+\\Theta_1\\epsilon_{t-1}+...+\\Theta_q\\epsilon_{t-q}$\n",
        "\n",
        "where $\\mu$ is a mean term and $\\epsilon_t\\overset{iid}\\sim N(0,\\sigma^2)$ is a random error.\n",
        "\n",
        "Similar to an AR model, when fitting an MA model the key choice is q, the number of random shock lags.\n",
        "\n",
        "## Autoregressive Moving Average ARMA(p,q) Models\n",
        "\n",
        "ARMA(p,q) models are a combination of an AR and MA model:\n",
        "\n",
        "$X_t=\\mu+\\phi_1 X_{t-1}+...+\\phi_p X_{t-p}+\\epsilon_t+\\Theta_1\\epsilon_{t-1}+...+\\Theta_q\\epsilon_{t-q}$\n",
        "\n",
        "where $\\mu$ is a mean term and $\\epsilon_t\\overset{iid}\\sim N(0,\\sigma^2)$ is a random error.\n",
        "\n",
        "When fitting an ARMA model, we need to choose two things: p, the number of AR lags, and q, the number of MA lags.\n",
        "\n",
        "## Autoregressive Integrated Moving Average ARIMA(p,d,q) Models\n",
        "\n",
        "ARIMA(p,d,q) is an ARMA model with differencing.\n",
        "\n",
        "When fitting an ARIMA model we need to choose three things: p, the number of AR lags, q, the number of MA lags, and d, the number of differences to use.\n",
        "\n",
        "## Decomposition Models\n",
        "\n",
        "Decomposition models specify $X_t$ as a combination of a trend component ($T_t$), seasonal component ($S_t$), and an error component/residual ($E_t$) i.e. $X_t=f(T_t,S_t,E_t)$.\n",
        "\n",
        "Common decomposition forms are: $X_t=T_t+S_t+E_t$ or $X_t=T_t*S_t*E_t$ (where then take logs to recover the additive form).\n",
        "\n",
        "There are various ways to estimate the different trend components: exponential smoothing, state space models/Kalman filtering, STL models, etc.\n",
        "\n",
        "In this project we will cover STL models because of their ease of use and flexibility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSPZWcyBrqKx",
        "colab_type": "text"
      },
      "source": [
        "# Fitting AR/MA/ARMA/ARIMA models with the Box Jenkins Method\n",
        "\n",
        "We will now go over how to fit AR/MA/ARMA/ARIMA models on a real data set and review a generic strategy for fitting them known as the Box Jenkins method. \n",
        "\n",
        "This process involves several steps to help identify the p, d, and q parameters that we need:\n",
        "\n",
        "- Identify whether the time series is stationary or not\n",
        "\n",
        "- Identify p, d, and q of the time series by\n",
        "\n",
        "  - Making the the time series stationary through differencing/detrending to find d\n",
        "  \n",
        "  - Looking at ACF/PACF to find p and q\n",
        "  \n",
        "  - Using model fit diagnostics like AIC or BIC to select the best model to find p, d, and q\n",
        "\n",
        "- Check the model fit using the Ljung–Box test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9TAIwbqrqKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data\n",
        "ur = read.csv(\"Data/Mass Monthly Unemployment Rate.csv\")\n",
        "head(ur);dim(ur)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fR415unrqK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check date class\n",
        "class(ur$DATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtKB4vCnrqK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#change date class to date type\n",
        "ur$DATE = as.Date(ur$DATE)\n",
        "class(ur$DATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA3v3mGprqK6",
        "colab_type": "text"
      },
      "source": [
        "## Checking for Stationarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjHvbpJHrqK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check time series plot\n",
        "ggplot(ur,aes(x=DATE,y=MAURN))+geom_line()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr_Ba1IkrqK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check ACF plot\n",
        "ggAcf(ur$MAURN,type='correlation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2ZNWrOlrqK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run ADF test\n",
        "adf.test(ur$MAURN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRf3cqBWrqLE",
        "colab_type": "text"
      },
      "source": [
        "## Transforming for Stationarity & Identifying Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzSB8gVorqLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fit AR model\n",
        "ar.model = auto.arima(ur$MAURN,max.d=0,max.q=0,allowdrift=T)\n",
        "ar.model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sV6eXborqLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fit MA model\n",
        "ma.model = auto.arima(ur$MAURN,max.d=0,max.p=0,allowdrift=T)\n",
        "ma.model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yoaRI8YrqLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fir ARMA model\n",
        "arma.model = auto.arima(ur$MAURN,max.d=0,allowdrift=T)\n",
        "arma.model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI0kjJA_rqLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fit ARIMA model\n",
        "arima.model = auto.arima(ur$MAURN,allowdrift=T)\n",
        "arima.model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRzXBxqurqLQ",
        "colab_type": "text"
      },
      "source": [
        "## Checking the Residuals of the Model Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unEQGelJrqLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculate residuals of each model\n",
        "ar.residual = resid(ar.model)\n",
        "ma.residual = resid(ma.model)\n",
        "arma.residual = resid(arma.model)\n",
        "arima.residual = resid(arima.model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN3b1h5PrqLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot PACF plot of each models residuals\n",
        "ggAcf(ar.residual,type='partial')\n",
        "ggAcf(ma.residual,type='partial')\n",
        "ggAcf(arma.residual,type='partial')\n",
        "ggAcf(arima.residual,type='partial')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJbzGY00rqLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run the Ljung Box test on the residuals\n",
        "Box.test(ar.residual,type=\"Ljung-Box \",lag=1)\n",
        "Box.test(ma.residual,type=\"Ljung-Box \",lag=1)\n",
        "Box.test(arma.residual,type=\"Ljung-Box \",lag=1)\n",
        "Box.test(arima.residual,type=\"Ljung-Box \",lag=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTxnSFKkrqLa",
        "colab_type": "text"
      },
      "source": [
        "## Making a forecast for each model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZUdipJJrqLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make forecast for each model\n",
        "ar.forecast = forecast(ar.model,h=24,level=80)\n",
        "ma.forecast = forecast(ma.model,h=24,level=80)\n",
        "arma.forecast = forecast(arma.model,h=24,level=80)\n",
        "arima.forecast = forecast(arima.model,h=24,level=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsZEBoKrqLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot forecast for each model\n",
        "g1 = autoplot(ar.forecast)\n",
        "g2 = autoplot(ma.forecast)\n",
        "g3 = autoplot(arma.forecast)\n",
        "g4 = autoplot(arima.forecast)\n",
        "grid.arrange(g1,g2,g3,g4,nrow=2,ncol=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXK1KENorqLe",
        "colab_type": "text"
      },
      "source": [
        "# Fitting Seasonal Trend Loess (STL) Decomposition Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YxpnF7XrqLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transform to time series object; need to specify frequency\n",
        "ur.ts = ts(ur$MAURN,frequency=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPgIM8FirqLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fit stil model\n",
        "stl.model=stl(ur.ts,s.window='periodic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-bcvPiIrqLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot model fit\n",
        "autoplot(stl.model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJzRVQCDrqLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make forecast\n",
        "stl.forecast = forecast(stl.model,h=24,level=80)\n",
        "autoplot(stl.forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIUD_hG2rqLm",
        "colab_type": "text"
      },
      "source": [
        "# Where to go Next\n",
        "\n",
        "- Advanced time series models\n",
        "  - ARCH, GARCH, etc. that model changing variance over time\n",
        "- Vector Autoregression (VAR)\n",
        "  - For multivariate i.e. multiple time series and modeling dependencies between them\n",
        "- Machine Learning\n",
        "  - How to do CV with time series\n",
        "  - Neural networks for sequence data (LSTMs, etc.)\n",
        "- Spatial Statistics\n",
        "  - Generalize time dependence to spatial dependence in multiple dimensions\n",
        "- Econometrics\n",
        "  - Cointegration\n",
        "  - Granger Causality\n",
        "  - Serial correlation\n",
        "  - Regression with time series data\n",
        "- Bayesian time series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoMVHR97rqLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}